# ver. 1.0.2
# meta developer: @Hikimuro

from .. import loader, utils
import cloudscraper
import random
import logging
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

@loader.tds
class FapReactorMod(loader.Module):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å fapreactor.com –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""

    strings = {
        "name": "FapReactor",
        "no_category": "‚ùå –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π .setfapcategory <–∫–∞—Ç–µ–≥–æ—Ä–∏—è>",
        "not_found": "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n\n–ü—Ä–∏—á–∏–Ω–∞: {}",
        "downloading": "üîç –ò—â—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "category", 
                None, 
                lambda: "–†–∞–∑–¥–µ–ª —Å fapreactor.com (–Ω–∞–ø—Ä–∏–º–µ—Ä: hentai, porn –∏ —Ç.–¥.)"
            )
        )
        self.scraper = cloudscraper.create_scraper()

    @loader.command()
    async def setfapcategory(self, message):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é (—Ä–∞–∑–¥–µ–ª)"""
        args = utils.get_args_raw(message)
        if not args:
            await message.edit("‚ö†Ô∏è –£–∫–∞–∂–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é.")
            return
        self.set("category", args)
        await message.edit(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞: `{args}`")

    @loader.command()
    async def fap(self, message):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞–Ω–¥–æ–º–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å fapreactor.com"""
        category = self.get("category")
        if not category:
            await message.edit(self.strings("no_category"))
            return

        await message.edit(self.strings("downloading"))

        try:
            page = random.randint(1, 10)
            url = f"https://fapreactor.com/tag/{category}/all/{page}"
            r = self.scraper.get(url, timeout=10)
            r.raise_for_status()

            soup = BeautifulSoup(r.text, "html.parser")
            posts = soup.select("div.post_content div.image a img")

            if not posts:
                raise ValueError("–°–µ–ª–µ–∫—Ç–æ—Ä div.post_content div.image a img –Ω–µ –Ω–∞—à—ë–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")

            images = [img["src"] for img in posts if "src" in img.attrs]
            image_url = random.choice(images)

            if image_url.startswith("//"):
                image_url = "https:" + image_url

            await message.client.send_file(message.chat_id, image_url)
            await message.delete()

        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å fapreactor")
            await message.edit(self.strings("not_found").format(str(e)))
